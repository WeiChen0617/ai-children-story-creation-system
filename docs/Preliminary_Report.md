---
marp: true
theme: default
paginate: true
footer: AI增强儿童故事创作 · 第三次小组会议展示
---

# AI增强儿童故事创作系统


## 目录

1. [项目概述与研究目标](#1-项目概述与研究目标)
2. [系统架构与技术实现](#2-系统架构与技术实现)
3. [Prompt工程与实验方法](#3-prompt工程与实验方法)
4. [系统实现与初步结果](#4-系统实现与初步结果)
5. [评估框架与实验设计](#5-评估框架与实验设计)
6. [伦理考虑与偏见控制](#6-伦理考虑与偏见控制)
7. [待讨论问题](#7-待讨论问题)
8. [参考文献](#8-参考文献)

---

## 1. 项目概述与研究目标

### 研究背景：

- 儿童创意写作有助于语言能力、情感表达与价值观建构（CoAuthor, 2022）
- 教育实践中存在故事创作效率低、内容适配难等问题
- 大语言模型（如 GPT-4）具备语言生成潜力，但在儿童内容生成方面仍缺乏：
  - 内容控制能力
  - 适龄语言支持
  - 教育性引导机制

### 年龄段选择依据：

- 本研究聚焦 **5–8 岁**儿童：
  - 该阶段语言发育迅速，正处于阅读启蒙与道德认知初期
  - 具备理解简单句式、识别正向行为的能力
  - 是语言习得和价值养成的关键窗口期

### 研究目标：

- 构建一个面向教育场景的 AI 故事创作系统
- 支持适龄性控制与教育导向的 Prompt 工程
- 建立集成自动评估与用户反馈的创作闭环机制

### 项目创新与贡献：

- 提出儿童内容创作中"Prompt + 可读性 + 教育性"三重控制框架
- 设计结构化 Prompt 模板适配不同主题与表达风格
- 构建可扩展的系统原型，支持用户交互与评价反馈

参考文献：Lee et al., 2022；Huang et al., 2024

---

## 2. 系统架构与技术实现

### 系统结构图：

<div style="text-align: center;">
<img src="./system_architecture.png" width="400" height="650" alt="系统架构图">
</div>

### 模块功能说明：

- **Prompt构造模块**：
  - 输入结构化关键词（角色、主题、语气）生成高控制性Prompt
  - 支持多种策略（模板式、问句式、结构式）

- **故事生成模块**：
  - 接入OpenAI API，默认使用GPT-3.5，支持切换GPT-4
  - 模型参数可调（温度、max tokens等）

- **可读性分析模块**：
  - 基于Textstat库，输出Flesch Reading Ease、句长、词长等指标
  - 提供语言难度等级建议（适合年龄段）

- **反馈采集与数据归档模块**：
  - 用户打分+主观评价归档
  - 生成个性化优化建议（如Prompt结构调整）

### 系统可扩展性设计：

- 接口标准化：各模块通过函数调用/JSON交互，支持独立替换
- 模型适配灵活：可引入Claude、Gemini等其他LLM替代
- 输出方式可拓展：可添加图文混排、语音生成、中文版本等

参考文献：Siddiqui et al., 2025（Script&Shift）

---

## 3. Prompt工程与实验方法

### Prompt设计策略：

- 基于教育主题与语言复杂度构建控制性Prompt
- 支持多种形式：模板式 / 问句式 / 结构式
- 每种Prompt风格设计多个变体以增强泛化能力

### Prompt示例：

**模板式：**
> 请为5–8岁的儿童写一个关于"合作"的原创故事。主角是一只小狐狸，语言简洁，积极正面，字数不超过300词。

**结构式：**
> 请分三段讲述一个儿童故事：1）介绍主人公；2）经历挑战；3）得到成长。主题为"诚实"，适合6岁儿童。

**问句式：**
> 什么是环保？请通过一则适合7岁儿童的故事解释这个问题。语言应通俗、有趣，表达积极价值观。

### 实验样本设置：

- **样本数量**：预计每种Prompt策略生成25-35篇故事样本进行测试
- **模型版本**：GPT-3.5 和 GPT-4 各生成一组样本，进行对比实验  
- **控制变量**：主题、结构、字数限制、风格引导方式保持一致

### 可重复性保障：

- 所有Prompt模板编号与版本控制（v1.0、v1.1等）
- 记录生成参数（temperature、max_tokens等）
- 实验生成日志与样本内容统一归档，便于后续复现与比较

参考文献：Shin et al., 2020（AutoPrompt）；Lee et al., 2022（CoAuthor）

---

## 4. 系统实现与初步结果

### 方案实现：

- 计划使用 Streamlit 实现原型系统，初步设计的功能模块包括：
  - 用户输入界面（关键词、主题设定）
  - Prompt构造器（可选结构化模板）
  - LLM生成接口（OpenAI GPT-3.5 / GPT-4）
  - 可读性分析集成（Textstat：Flesch Reading Ease 等）
  - 结果输出与反馈评分界面

### 界面结构：

- 左侧：关键词/主题输入，Prompt样式选择器
- 中部：系统生成故事内容（自动滚动）
- 右侧：自动可读性评分 + 用户反馈打分（Likert量表）

### 初步输出示例：

- **标题**：小狐狸建桥记  
- **生成模型**：GPT-3.5  
- **Prompt策略**：模板式  
- **Flesch Reading Ease**：预期将控制在80-90范围  
- **推荐阅读年龄**：6–7岁  
- **自动分析摘要**：
  - 平均句长：9.2词
  - 教育关键词命中率：100%（合作、帮助、分享）

参考文献：Lee et al., 2022（CoAuthor）

---

## 5. 评估框架与实验设计

### 评估方法概述：

本研究采用**自动评估 + 用户评估**结合方式，综合衡量故事生成的质量、适龄性与教育有效性。

---

### 自动评估指标：

| 指标 | 说明 |
|------|------|
| Flesch Reading Ease | 评估文本可读性，匹配年龄段 |
| 平均句长 / 词长 | 反映语言复杂度 |
| 教育关键词覆盖率 | 判断故事主题控制能力 |

- 自动指标计算由 Textstat 库实现，评分结果将与儿童年龄段标准对应分析（FRE ≥ 80 对应6–8岁）

---

### 用户评估指标（问卷 + 打分）：

| 维度 | 内容 | 评分标准 |
|------|------|-----------|
| 教育性 | 是否传达明确正向教育主题 | 5分量表，≥4为有效 |
| 语言适龄性 | 是否符合目标年龄段阅读能力 | 由教师判断 |
| 风格一致性 | 故事情节是否连贯、语言是否自然 | 语言流畅度评分 |

- 用户样本：小学教师与家长各5人，总计N≈10
- 每篇故事至少被两位独立评估者打分

---

### 数据处理与分析方法：

- 自动评估结果与用户评分进行**皮尔逊相关分析**
- 不同Prompt策略、模型版本的生成效果对比采用**配对t检验**
- 用户评价将采用**平均值 + 标准差 + 主观反馈摘录**多维展示

参考文献：Gómez-Rodríguez et al., 2023；Lee et al., 2022

---

## 6. 伦理考虑与偏见控制

### 潜在伦理风险分析：

| 类型 | 可能问题 | 影响群体 |
|------|----------|-----------|
| 性别刻板印象 | 女性角色常被描述为柔弱、感性 | 儿童性别认知偏差 |
| 文化偏向 | 内容中隐含特定国家/种族设定 | 非主流文化家庭 |
| 情绪倾向偏差 | 负面情绪描写比例不当 | 情绪敏感儿童 |
| 数据隐私 | 用户反馈数据未经授权存储 | 教师/家长个人信息泄露 |

---

### 应对策略与控制方法：

- **内容适龄性控制：**
  - 所有Prompt均限定语言简洁度与故事结构
  - 自动评分（FRE）与教育主题匹配机制强制筛选不适文本
  - 用户可标记"不适合"内容并加入再训练筛选集

- **偏见识别与修正：**
  - 使用关键词分析法检测性别描述、文化特征频次
  - 建立性别中立Prompt模板，避免引导性设定（如"漂亮的女孩"）
  - 教育主题设定以价值观为导向（如诚实、环保、合作）

- **数据隐私与伦理合规：**
  - 所有用户数据匿名存储，不收集个人敏感信息
  - 获取问卷反馈前提供使用说明与研究知情同意书
  - 如涉及未成年人评价数据，将经学校或导师审批程序

参考文献：Huang et al., 2024（GPT-WritingPrompts）；Siddiqui et al., 2025（Script&Shift）

---


## 7. 待讨论问题

1. 数据采集是否需要申请伦理审批？
2. 系统后续是否支持多媒体内容生成？
3. 项目动机相关的文献是否有推荐？

---

## 8. 参考文献

1. Shin et al. (2020). *AutoPrompt: Eliciting Knowledge from Language Models with Automatically Generated Prompts*. EMNLP.  
2. Lee et al. (2022). *CoAuthor: Designing a Human-AI Collaborative Writing Dataset*. CHI '22.  
3. Gómez-Rodríguez et al. (2023). *A Confederacy of Models: Evaluation of LLMs on Creative Writing*.  
4. Huang et al. (2024). *GPT-WritingPrompts Dataset: Character Portrayal Analysis*.  
5. Siddiqui et al. (2025). *Script&Shift: Layered Interfaces for LLM Writing Assistants*. CHI '25.
